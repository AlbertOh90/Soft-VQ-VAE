{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6812,
     "status": "ok",
     "timestamp": 1557997274980,
     "user": {
      "displayName": "Albert Oh",
      "photoUrl": "https://lh3.googleusercontent.com/-QG23SXF4tiU/AAAAAAAAAAI/AAAAAAAAACc/zl1lagMUhDI/s64/photo.jpg",
      "userId": "18363562762415482882"
     },
     "user_tz": -120
    },
    "id": "v2HQdVB9sPoz",
    "outputId": "f682a6b6-9433-4083-d6a5-b3f27d00da5a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "local_data_dir = './Datasets/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8229,
     "status": "ok",
     "timestamp": 1557997276413,
     "user": {
      "displayName": "Albert Oh",
      "photoUrl": "https://lh3.googleusercontent.com/-QG23SXF4tiU/AAAAAAAAAAI/AAAAAAAAACc/zl1lagMUhDI/s64/photo.jpg",
      "userId": "18363562762415482882"
     },
     "user_tz": -120
    },
    "id": "m3SERNaFwH-y",
    "outputId": "09a7fbba-350b-4f0e-b96c-f38d3fb42c71"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import tempfile, pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "from tensorflow.python.training import moving_averages\n",
    "\n",
    "from six.moves import urllib\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F7CuerH5tGdY"
   },
   "outputs": [],
   "source": [
    "def cast_and_normalise_images(data_dict):\n",
    "  \"\"\"Convert images to floating point with the range [0.5, 0.5]\"\"\"\n",
    "  images = data_dict['images']\n",
    "  data_dict['images'] = (tf.cast(images, tf.float32) / 255.0) - 0.5\n",
    "  return data_dict\n",
    "\n",
    "temp_train= np.load(local_data_dir+\"train_data_dict.npy\",allow_pickle=True)\n",
    "train_data_dict = temp_train.item()\n",
    "temp_test= np.load(local_data_dir+\"test_data_dict.npy\",allow_pickle=True)\n",
    "test_data_dict = temp_test.item()\n",
    "\n",
    "data_variance = np.var(train_data_dict['images'] / 255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvwQwxW4uXVk"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, AveragePooling2D, UpSampling2D\n",
    "class Encoder():\n",
    "  def __init__(self, num_hiddens, name='encoder'):\n",
    "    self._num_hiddens = num_hiddens\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    h = Conv2D(filters=int(self._num_hiddens),\n",
    "               kernel_size=3,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               #kernel_initializer= 'RandomNormal',\n",
    "               padding='same')(x)\n",
    "    \n",
    "    h = Conv2D(filters=int(self._num_hiddens*2),\n",
    "               kernel_size=3,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               #kernel_initializer= 'RandomNormal',\n",
    "               padding='same')(h)\n",
    "    \n",
    "    h = Conv2D(filters=int(self._num_hiddens*4),\n",
    "               kernel_size=3,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "              # kernel_initializer= 'RandomNormal',\n",
    "               padding='same')(h)\n",
    "    \n",
    "    h = Conv2D(filters=int(self._num_hiddens*8),\n",
    "               kernel_size=3,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               kernel_initializer= 'RandomNormal',\n",
    "               padding='same')(h)\n",
    "    #h = AveragePooling2D()(h)\n",
    "    \n",
    "    return h\n",
    "\n",
    "  #Last layer should not have any activiation functions or sigmoid.\n",
    "class Decoder():\n",
    "  def __init__(self, num_hiddens, name='decoder'):\n",
    "    self._num_hiddens = num_hiddens\n",
    "  \n",
    "  def __call__(self, x):  \n",
    "        \n",
    "    #h = UpSampling2D()(x)\n",
    "    h = Conv2DTranspose(filters=int(self._num_hiddens*8),\n",
    "                        kernel_size=3,\n",
    "                        activation='relu',\n",
    "                        strides=2,\n",
    "                        kernel_initializer= 'RandomNormal',\n",
    "                        padding='same')(x)\n",
    "    \n",
    "    \n",
    "    h = Conv2DTranspose(filters=int(self._num_hiddens*4),\n",
    "                        kernel_size=3,\n",
    "                        activation='relu',\n",
    "                        strides=2,\n",
    "                      #  kernel_initializer= 'RandomNormal',\n",
    "                        padding='same')(h)\n",
    "    \n",
    "    h = Conv2DTranspose(filters=int(self._num_hiddens*2),\n",
    "                        kernel_size=3,\n",
    "                        activation='relu',\n",
    "                        strides=2,\n",
    "                     #   kernel_initializer= 'RandomNormal',\n",
    "                        padding='same')(h)\n",
    "\n",
    "      \n",
    "    x_recon = Conv2DTranspose(filters=3,\n",
    "                        kernel_size=3,\n",
    "                        strides=2,\n",
    "                     #   kernel_initializer= 'RandomNormal',\n",
    "                        padding='same')(h)\n",
    "    return x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XOnqCwstunZ2"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Reshape\n",
    "from keras import backend as K\n",
    "from keras.initializers import RandomUniform\n",
    "\n",
    "def bottleneck_flatten(input_signal,latent_dim, num_codewords):\n",
    "    # shape info needed to build decoder model\n",
    "    shape = K.int_shape(input_signal)\n",
    "    input_signal = Flatten()(input_signal)\n",
    "    #dense is not flattened as the document suggest\n",
    "    x = Dense(latent_dim)(input_signal)\n",
    "    y = Dense(num_codewords)(input_signal)\n",
    "    return {'z_mean':x, \n",
    "            'z_log_var': y,\n",
    "            'shape':shape}\n",
    "\n",
    "def bottleneck_deflatten(input_signal, shape):\n",
    "    x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(input_signal)\n",
    "    #x = Dense(shape[1], activation='relu')(input_signal)\n",
    "    deflated = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "    #deflated = Reshape((1, 1, shape[1]))(x)\n",
    "    return deflated \n",
    "  \n",
    "def bottleneck_concatenation(input_signal, embedding_dim, num_codewords):\n",
    "    shape = K.int_shape(input_signal)\n",
    "    x = Conv2D(filters= embedding_dim,\n",
    "               kernel_size=3,\n",
    "              # activation='relu',\n",
    "               strides=1,\n",
    "            #   kernel_initializer= 'RandomNormal',\n",
    "               padding='same')(input_signal)\n",
    "    y = Conv2D(filters= num_codewords,\n",
    "               kernel_size=3,\n",
    "             #  activation='relu',\n",
    "               strides=1,\n",
    "            #   kernel_initializer= 'RandomNormal',\n",
    "               padding='same')(input_signal)\n",
    "    return {'z_mean':x, \n",
    "            'z_log_var': y,\n",
    "            'shape':shape}\n",
    "\n",
    "def sampling(z_mean, z_log_var):\n",
    "    sampling_dim = tf.shape(z_mean)\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    epsilon = tf.random_normal(sampling_dim)\n",
    "    return z_mean + tf.sqrt(tf.exp( z_log_var)) * epsilon\n",
    "  \n",
    "def information_dropout(z_mean, sigma=None, sigma0=1.):\n",
    "    sampling_dim = tf.shape(z_mean)\n",
    "    e = tf.random_normal(sampling_dim)\n",
    "    log_normal = tf.exp(sigma * sigma0 * e)\n",
    "    return tf.multiply(z_mean, log_normal)\n",
    "  \n",
    "def rbf_prob(dist, smooth):\n",
    "    prob = tf.exp(-tf.multiply(dist, 0.5*smooth))\n",
    "    probs = prob/tf.expand_dims(tf.reduce_sum(prob, 1),1)\n",
    "    return probs\n",
    "\n",
    "def add_noise(input_signal, noise_level):\n",
    "    dims = tf.shape(input_signal)\n",
    "    # by default, random_normal has mean=0 and std=1.0\n",
    "    noise = tf.random_normal(dims, stddev = noise_level)\n",
    "    return input_signal + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHnV3fiVuvig"
   },
   "outputs": [],
   "source": [
    "class OhVectorQuantizer():\n",
    "  # b: batch size; q: number of channels; K: number of codewords; d:embedding_dim; \n",
    "  def __init__(self, embedding_dim, num_embeddings, commitment_cost, name='vq_layer'):\n",
    "    self._embedding_dim = embedding_dim\n",
    "    self._num_embeddings = num_embeddings\n",
    "    self._commitment_cost = commitment_cost\n",
    "\n",
    "    initializer = tf.initializers.variance_scaling()\n",
    "    self._w = tf.get_variable('embedding', [self._embedding_dim, self._num_embeddings], initializer=initializer, trainable=True)\n",
    "  \n",
    "\n",
    "  def __call__(self, inputs, is_training):\n",
    "        #noisy\n",
    "        #inputs['z_mean'] = add_noise(inputs['z_mean'], 0.01)\n",
    "        # Assert last dimension is same as self._embedding_dim\n",
    "        w = self._w.read_value()\n",
    "      \n",
    "        # shape: [batch, num_channel, embedding_dim]\n",
    "        input_shape = tf.shape(inputs['z_mean'])\n",
    "        with tf.control_dependencies([\n",
    "            tf.Assert(tf.equal(input_shape[-1], self._embedding_dim),[input_shape])]):\n",
    "            flat_inputs = tf.reshape(inputs['z_mean'], [-1, self._embedding_dim])\n",
    "            flat_smooth = tf.reshape(inputs['z_log_var'], [-1, self._num_embeddings])\n",
    "\n",
    "         # distances dimension: (b*q)*K\n",
    "        distances = (tf.reduce_sum(flat_inputs**2, 1, keepdims=True)\n",
    "                     - 2 * tf.matmul(flat_inputs, w)\n",
    "                     + tf.reduce_sum(w ** 2, 0, keepdims=True))\n",
    "        \n",
    "        #after shape: (b*q)*K\n",
    "        smooth = 1./tf.exp(flat_smooth)**2\n",
    "        probs = rbf_prob(distances, smooth)/tf.sqrt(smooth)\n",
    "        #After shape: (q*b,1,K)\n",
    "        probs = tf.expand_dims(probs, 1)\n",
    "        #After shape: (1,d,K)\n",
    "        codebook = tf.expand_dims(w, 0)\n",
    "        #expected shape: b*q*d\n",
    "        quantize_vector = tf.reduce_sum(codebook*probs,2)\n",
    "        quantized = tf.reshape(quantize_vector, tf.shape(inputs['z_mean']))\n",
    "    \n",
    "        #encoding_indices = tf.argmax(- distances, 1)\n",
    "        #values dimension: flat*2\n",
    "        #[values, encoding_indices] = tf.nn.top_k(-distances, k = 2)\n",
    "        #encoding_indices = tf.reshape(encoding_indices[:,0], input_shape[:-1])\n",
    "        #quantized = self.quantize(encoding_indices)\n",
    "\n",
    "        \n",
    "        e_latent_loss = tf.reduce_mean((tf.stop_gradient(quantized) - inputs['z_mean']) ** 2)\n",
    "        q_latent_loss = tf.reduce_mean((quantized - tf.stop_gradient(inputs['z_mean'])) ** 2)\n",
    "        loss = q_latent_loss + self._commitment_cost * e_latent_loss \n",
    "\n",
    "        quantized = inputs['z_mean'] + tf.stop_gradient(quantized - inputs['z_mean'])\n",
    "        \n",
    "        return {'quantize': quantized, 'loss': loss}\n",
    "    \n",
    "  @property\n",
    "  def embeddings(self):\n",
    "        return self._w\n",
    "  \n",
    "  def quantize(self, encoding_indices):\n",
    "        with tf.control_dependencies([encoding_indices]):\n",
    "            w = tf.transpose(self.embeddings.read_value(), [1, 0])\n",
    "        return tf.nn.embedding_lookup(w, encoding_indices, validate_indices=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16596,
     "status": "ok",
     "timestamp": 1557997284968,
     "user": {
      "displayName": "Albert Oh",
      "photoUrl": "https://lh3.googleusercontent.com/-QG23SXF4tiU/AAAAAAAAAAI/AAAAAAAAACc/zl1lagMUhDI/s64/photo.jpg",
      "userId": "18363562762415482882"
     },
     "user_tz": -120
    },
    "id": "Ry6--FM0uziY",
    "outputId": "a6722857-63bc-4116-f2f9-08b84e3032fa"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "batch_size = 64\n",
    "image_size = 32\n",
    "# Data Loading.\n",
    "train_dataset_iterator = (\n",
    "    tf.data.Dataset.from_tensor_slices(train_data_dict)\n",
    "    .map(cast_and_normalise_images)\n",
    "    .shuffle(10000)\n",
    "    .repeat(-1)  # repeat indefinitely\n",
    "    .batch(batch_size)).make_one_shot_iterator()\n",
    "classifer_dataset_iterator = (\n",
    "    tf.data.Dataset.from_tensor_slices(train_data_dict)\n",
    "    .map(cast_and_normalise_images)\n",
    "    .repeat(1)  # repeat indefinitely\n",
    "    .batch(73257)).make_initializable_iterator()\n",
    "test_dataset_iterator = (\n",
    "    tf.data.Dataset.from_tensor_slices(test_data_dict)\n",
    "    .map(cast_and_normalise_images)\n",
    "    .repeat(1)  # 1 epoch\n",
    "    .batch(26032)).make_initializable_iterator()\n",
    "train_dataset_batch = train_dataset_iterator.get_next()\n",
    "classifer_dataset_batch = classifer_dataset_iterator.get_next()\n",
    "test_dataset_batch = test_dataset_iterator.get_next()\n",
    "\n",
    "def get_images(sess, subset='train'):\n",
    "    if subset == 'train':\n",
    "        return sess.run(train_dataset_batch)['images']\n",
    "    elif subset =='classifer':\n",
    "        return sess.run(classifer_dataset_batch)\n",
    "    elif subset == 'test':\n",
    "        return sess.run(test_dataset_batch)['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16574,
     "status": "ok",
     "timestamp": 1557997284970,
     "user": {
      "displayName": "Albert Oh",
      "photoUrl": "https://lh3.googleusercontent.com/-QG23SXF4tiU/AAAAAAAAAAI/AAAAAAAAACc/zl1lagMUhDI/s64/photo.jpg",
      "userId": "18363562762415482882"
     },
     "user_tz": -120
    },
    "id": "pdrQaFM3vEUf",
    "outputId": "0f65f285-bc8a-45a0-f6cb-4ef247102395"
   },
   "outputs": [],
   "source": [
    "# 100k steps should take < 30 minutes on a modern (>= 2017) GPU.\n",
    "num_training_updates = 10000\n",
    "num_channels = 64\n",
    "\n",
    "# This value is not that important, usually 64 works. This will not change the capacity in the information-bottleneck.\n",
    "sub_dim = 64\n",
    "num_latents = 4\n",
    "embedding_dim = sub_dim*num_latents\n",
    "\n",
    "# The higher this value, the higher the capacity in the information bottleneck.\n",
    "num_embeddings = 32\n",
    "\n",
    "# commitment_cost should be set appropriately. It's often useful to try a couple\n",
    "# of values. It mostly depends on the scale of the reconstruction cost\n",
    "# (log p(x|z)). So if the reconstruction cost is 100x higher, the\n",
    "# commitment_cost should also be multiplied with the same amount.\n",
    "commitment_cost = 7.5\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# Build modules.\n",
    "encoder = Encoder(num_channels)\n",
    "decoder = Decoder(num_channels)\n",
    "vq_vae = OhVectorQuantizer(\n",
    "    embedding_dim=embedding_dim,\n",
    "    num_embeddings=num_embeddings,\n",
    "    commitment_cost=commitment_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10339
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1141077,
     "status": "ok",
     "timestamp": 1557998409488,
     "user": {
      "displayName": "Albert Oh",
      "photoUrl": "https://lh3.googleusercontent.com/-QG23SXF4tiU/AAAAAAAAAAI/AAAAAAAAACc/zl1lagMUhDI/s64/photo.jpg",
      "userId": "18363562762415482882"
     },
     "user_tz": -120
    },
    "id": "Z9UiisLpvI_J",
    "outputId": "18928869-0a06-40d0-9461-8ed2e845b990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "100 iterations\n",
      "recon_error: 0.724\n",
      "\n",
      "200 iterations\n",
      "recon_error: 0.506\n",
      "\n",
      "300 iterations\n",
      "recon_error: 0.347\n",
      "\n",
      "400 iterations\n",
      "recon_error: 0.323\n",
      "\n",
      "500 iterations\n",
      "recon_error: 0.313\n",
      "\n",
      "600 iterations\n",
      "recon_error: 0.272\n",
      "\n",
      "700 iterations\n",
      "recon_error: 0.256\n",
      "\n",
      "800 iterations\n",
      "recon_error: 0.244\n",
      "\n",
      "900 iterations\n",
      "recon_error: 0.228\n",
      "\n",
      "1000 iterations\n",
      "recon_error: 0.223\n",
      "\n",
      "1100 iterations\n",
      "recon_error: 0.213\n",
      "\n",
      "1200 iterations\n",
      "recon_error: 0.206\n",
      "\n",
      "1300 iterations\n",
      "recon_error: 0.203\n",
      "\n",
      "1400 iterations\n",
      "recon_error: 0.200\n",
      "\n",
      "1500 iterations\n",
      "recon_error: 0.199\n",
      "\n",
      "1600 iterations\n",
      "recon_error: 0.199\n",
      "\n",
      "1700 iterations\n",
      "recon_error: 0.195\n",
      "\n",
      "1800 iterations\n",
      "recon_error: 0.197\n",
      "\n",
      "1900 iterations\n",
      "recon_error: 0.189\n",
      "\n",
      "2000 iterations\n",
      "recon_error: 0.184\n",
      "\n",
      "2100 iterations\n",
      "recon_error: 0.184\n",
      "\n",
      "2200 iterations\n",
      "recon_error: 0.183\n",
      "\n",
      "2300 iterations\n",
      "recon_error: 0.177\n",
      "\n",
      "2400 iterations\n",
      "recon_error: 0.180\n",
      "\n",
      "2500 iterations\n",
      "recon_error: 0.181\n",
      "\n",
      "2600 iterations\n",
      "recon_error: 0.179\n",
      "\n",
      "2700 iterations\n",
      "recon_error: 0.182\n",
      "\n",
      "2800 iterations\n",
      "recon_error: 0.172\n",
      "\n",
      "2900 iterations\n",
      "recon_error: 0.169\n",
      "\n",
      "3000 iterations\n",
      "recon_error: 0.167\n",
      "\n",
      "3100 iterations\n",
      "recon_error: 0.166\n",
      "\n",
      "3200 iterations\n",
      "recon_error: 0.163\n",
      "\n",
      "3300 iterations\n",
      "recon_error: 0.161\n",
      "\n",
      "3400 iterations\n",
      "recon_error: 0.162\n",
      "\n",
      "3500 iterations\n",
      "recon_error: 0.162\n",
      "\n",
      "3600 iterations\n",
      "recon_error: 0.159\n",
      "\n",
      "3700 iterations\n",
      "recon_error: 0.158\n",
      "\n",
      "3800 iterations\n",
      "recon_error: 0.162\n",
      "\n",
      "3900 iterations\n",
      "recon_error: 0.159\n",
      "\n",
      "4000 iterations\n",
      "recon_error: 0.152\n",
      "\n",
      "4100 iterations\n",
      "recon_error: 0.153\n",
      "\n",
      "4200 iterations\n",
      "recon_error: 0.149\n",
      "\n",
      "4300 iterations\n",
      "recon_error: 0.151\n",
      "\n",
      "4400 iterations\n",
      "recon_error: 0.145\n",
      "\n",
      "4500 iterations\n",
      "recon_error: 0.145\n",
      "\n",
      "4600 iterations\n",
      "recon_error: 0.143\n",
      "\n",
      "4700 iterations\n",
      "recon_error: 0.143\n",
      "\n",
      "4800 iterations\n",
      "recon_error: 0.143\n",
      "\n",
      "4900 iterations\n",
      "recon_error: 0.139\n",
      "\n",
      "5000 iterations\n",
      "recon_error: 0.141\n",
      "\n",
      "5100 iterations\n",
      "recon_error: 0.139\n",
      "\n",
      "5200 iterations\n",
      "recon_error: 0.139\n",
      "\n",
      "5300 iterations\n",
      "recon_error: 0.138\n",
      "\n",
      "5400 iterations\n",
      "recon_error: 0.139\n",
      "\n",
      "5500 iterations\n",
      "recon_error: 0.137\n",
      "\n",
      "5600 iterations\n",
      "recon_error: 0.138\n",
      "\n",
      "5700 iterations\n",
      "recon_error: 0.136\n",
      "\n",
      "5800 iterations\n",
      "recon_error: 0.134\n",
      "\n",
      "5900 iterations\n",
      "recon_error: 0.136\n",
      "\n",
      "6000 iterations\n",
      "recon_error: 0.131\n",
      "\n",
      "6100 iterations\n",
      "recon_error: 0.133\n",
      "\n",
      "6200 iterations\n",
      "recon_error: 0.129\n",
      "\n",
      "6300 iterations\n",
      "recon_error: 0.127\n",
      "\n",
      "6400 iterations\n",
      "recon_error: 0.127\n",
      "\n",
      "6500 iterations\n",
      "recon_error: 0.123\n",
      "\n",
      "6600 iterations\n",
      "recon_error: 0.126\n",
      "\n",
      "6700 iterations\n",
      "recon_error: 0.124\n",
      "\n",
      "6800 iterations\n",
      "recon_error: 0.120\n",
      "\n",
      "6900 iterations\n",
      "recon_error: 0.119\n",
      "\n",
      "7000 iterations\n",
      "recon_error: 0.118\n",
      "\n",
      "7100 iterations\n",
      "recon_error: 0.119\n",
      "\n",
      "7200 iterations\n",
      "recon_error: 0.119\n",
      "\n",
      "7300 iterations\n",
      "recon_error: 0.118\n",
      "\n",
      "7400 iterations\n",
      "recon_error: 0.114\n",
      "\n",
      "7500 iterations\n",
      "recon_error: 0.115\n",
      "\n",
      "7600 iterations\n",
      "recon_error: 0.111\n",
      "\n",
      "7700 iterations\n",
      "recon_error: 0.111\n",
      "\n",
      "7800 iterations\n",
      "recon_error: 0.111\n",
      "\n",
      "7900 iterations\n",
      "recon_error: 0.109\n",
      "\n",
      "8000 iterations\n",
      "recon_error: 0.108\n",
      "\n",
      "8100 iterations\n",
      "recon_error: 0.109\n",
      "\n",
      "8200 iterations\n",
      "recon_error: 0.108\n",
      "\n",
      "8300 iterations\n",
      "recon_error: 0.109\n",
      "\n",
      "8400 iterations\n",
      "recon_error: 0.108\n",
      "\n",
      "8500 iterations\n",
      "recon_error: 0.104\n",
      "\n",
      "8600 iterations\n",
      "recon_error: 0.106\n",
      "\n",
      "8700 iterations\n",
      "recon_error: 0.106\n",
      "\n",
      "8800 iterations\n",
      "recon_error: 0.104\n",
      "\n",
      "8900 iterations\n",
      "recon_error: 0.104\n",
      "\n",
      "9000 iterations\n",
      "recon_error: 0.104\n",
      "\n",
      "9100 iterations\n",
      "recon_error: 0.102\n",
      "\n",
      "9200 iterations\n",
      "recon_error: 0.099\n",
      "\n",
      "9300 iterations\n",
      "recon_error: 0.101\n",
      "\n",
      "9400 iterations\n",
      "recon_error: 0.101\n",
      "\n",
      "9500 iterations\n",
      "recon_error: 0.098\n",
      "\n",
      "9600 iterations\n",
      "recon_error: 0.098\n",
      "\n",
      "9700 iterations\n",
      "recon_error: 0.092\n",
      "\n",
      "9800 iterations\n",
      "recon_error: 0.098\n",
      "\n",
      "9900 iterations\n",
      "recon_error: 0.097\n",
      "\n",
      "10000 iterations\n",
      "recon_error: 0.096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, image_size, image_size, 3))\n",
    "\n",
    "#AE\n",
    "#z = bottleneck_flatten(encoder(x), embedding_dim, num_embeddings)\n",
    "#input_decoder = bottleneck_deflatten(z['z_mean'],z['shape'])\n",
    "#VAE\n",
    "#z = bottleneck_concatenation(encoder(x), sub_dim, sub_dim)\n",
    "#samples = sampling(z['z_mean'], z['z_log_var'])\n",
    "#input_decoder = samples\n",
    "#Information dropout\n",
    "#z = bottleneck_concatenation(encoder(x), sub_dim, sub_dim)\n",
    "#samples = information_dropout(z['z_mean'], sigma = 0.7*z['z_log_var'])\n",
    "#input_decoder = samples\n",
    "#vq-vae,\n",
    "#z= bottleneck_concatenation(encoder(x), sub_dim, num_embeddings)\n",
    "#vq_output_train = vq_vae(z, is_training=True)\n",
    "#input_decoder = vq_output_train[\"quantize\"]\n",
    "z = bottleneck_flatten(encoder(x), embedding_dim, num_embeddings)\n",
    "vq_output_train = vq_vae(z, is_training=True)\n",
    "input_decoder = bottleneck_deflatten(vq_output_train[\"quantize\"], z[\"shape\"])\n",
    "\n",
    "\n",
    "#AE\n",
    "#VAE\n",
    "#Information droupout\n",
    "#vq-vae\n",
    "x_recon = decoder(input_decoder)\n",
    "recon_error = tf.reduce_mean(tf.reduce_mean((x_recon - x)**2,[1,2,3])/data_variance)  # Normalized MSE\n",
    "\n",
    "#AE\n",
    "#loss = recon_error\n",
    "#VAE\n",
    "#kl_loss = -0.5*tf.reduce_sum(1.0 + z['z_log_var'] - tf.square(z['z_mean']) - tf.exp(z['z_log_var']),axis = 1)\n",
    "#loss = image_size*image_size*recon_error + 100.0*tf.reduce_mean(kl_loss)\n",
    "# Information dropout\n",
    "#dropout_cost = -tf.reduce_mean(tf.log(z['z_log_var']/0.7 + 0.001))\n",
    "#loss = image_size*image_size*recon_error + 0.5*dropout_cost\n",
    "#vq-vae\n",
    "#beta is the power of the vq quantizer.\n",
    "beta = 2.0\n",
    "loss = recon_error + beta*vq_output_train[\"loss\"]\n",
    "\n",
    "# Create optimizer and TF session.\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "#saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.train.SingularMonitoredSession()\n",
    "\n",
    "#Train.\n",
    "train_res_recon_error = []\n",
    "#train_ratio = []\n",
    "for i in xrange(num_training_updates):    \n",
    "    feed_dict = {x: get_images(sess)}\n",
    "    #results = sess.run([train_op, recon_error,ratio], feed_dict={x: get_images(sess),s_flag: s_f})\n",
    "    results = sess.run([train_op, recon_error], feed_dict={x: get_images(sess)})\n",
    "    train_res_recon_error.append(results[1])\n",
    "    #train_ratio.append(results[2])\n",
    "    \n",
    "    if (i+1) % 100 == 0:\n",
    "        print('%d iterations' % (i+1))\n",
    "        print('recon_error: %.3f' % np.mean(train_res_recon_error[-100:]))\n",
    "        print()\n",
    "    \n",
    "def get_session(sess):\n",
    "    session = sess\n",
    "    while type(session).__name__ != 'Session':\n",
    "        session = session._sess\n",
    "    return session \n",
    "#saver.save(get_session(sess),local_data_dir+'soft_vqvae.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3349
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1159292,
     "status": "error",
     "timestamp": 1557998427725,
     "user": {
      "displayName": "Albert Oh",
      "photoUrl": "https://lh3.googleusercontent.com/-QG23SXF4tiU/AAAAAAAAAAI/AAAAAAAAACc/zl1lagMUhDI/s64/photo.jpg",
      "userId": "18363562762415482882"
     },
     "user_tz": -120
    },
    "id": "ilqF_ut7vMd_",
    "outputId": "6ead8b0e-31bf-4e2b-8c7c-eae3ff3a9c32"
   },
   "outputs": [],
   "source": [
    "train_num = 50000\n",
    "test_num = 10000\n",
    "# get all the training latent representations\n",
    "encodings = []\n",
    "labels = []\n",
    "sess.run(classifer_dataset_iterator.initializer)\n",
    "train_wholebatch = get_images(sess,'classifer')\n",
    "encodings = sess.run(z[\"z_mean\"], feed_dict = {x: train_wholebatch['images'][0:train_num,:,:,:]}) \n",
    "encodings = np.reshape(encodings,(train_num,-1))\n",
    "labels = train_wholebatch['labels'][0:train_num]\n",
    "train_encodings = np.asarray(encodings)\n",
    "train_labels = np.squeeze(np.asarray(labels), axis = 1)\n",
    "\n",
    "# get all the test latent represetations\n",
    "test_encodings = []\n",
    "test_labels = []\n",
    "sess.run(test_dataset_iterator.initializer)\n",
    "test_wholebatch = get_images(sess, subset = 'test')\n",
    "encodings = sess.run(z[\"z_mean\"], feed_dict = {x: test_wholebatch[0:test_num,:,:,:]})\n",
    "encodings = np.reshape(encodings,(test_num,-1))\n",
    "labels = test_data_dict['labels'][0:test_num]\n",
    "test_encodings = np.asarray(encodings)\n",
    "test_labels = np.squeeze(np.asarray(labels), axis = 1)\n",
    "\n",
    "np.save(local_data_dir+'train_encodings.npy', train_encodings)\n",
    "np.save(local_data_dir+'train_labels.npy',train_labels)\n",
    "np.save(local_data_dir+'test_encodings.npy',test_encodings)\n",
    "np.save(local_data_dir+'test_labels',test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SVHN_classifer_train.ipynb",
   "provenance": [
    {
     "file_id": "1K5mxiCYaKiTNUHbfkXtf6A-iXLwDteK5",
     "timestamp": 1557693600632
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
